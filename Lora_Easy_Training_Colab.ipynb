{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGwaJ0eGHCkw"
      },
      "source": [
        "# LoRA Easy Training Colab\n",
        "[![Ko-Fi](https://img.shields.io/badge/Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat)](https://ko-fi.com/jelosus1)\n",
        "\n",
        "### Colab powered by [Lora_Easy_Training_Scripts_Backend](https://github.com/derrian-distro/LoRA_Easy_Training_scripts_Backend/)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Learn how to use the colab [here](https://civitai.com/articles/4409).\n",
        "\n",
        "If you feel something is missing, want something to be added or simply found a bug, open an [issue](https://github.com/Jelosus2/Lora_Easy_Training_Colab/issues).\n",
        "\n",
        "---\n",
        "\n",
        "Last Update: November 16, 2024. Check the [full changelog](https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#changelog)\n",
        "\n",
        "Changes:\n",
        "- Added emojis to make sections separation easy to the eyes.\n",
        "- Added Illustrious v0.1 and NoobAI 1.0 (Epsilon) to the list of default checkpoints available to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CSz_rmldHZvh",
        "cellView": "form",
        "outputId": "c643ada0-d58a-42b2-de89-204c31ec5146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing trainer...\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2 python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 6 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 3,987 kB of archives.\n",
            "After this operation, 8,325 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../1-libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../2-aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "Preparing to unpack .../3-python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../4-python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../5-python3.10-venv_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Cloning into '/content/trainer'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 334 (delta 150), reused 128 (delta 128), pack-reused 167 (from 1)\u001b[K\n",
            "Receiving objects: 100% (334/334), 7.79 MiB | 11.78 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n",
            "Submodule 'sd_scripts' (https://github.com/kohya-ss/sd-scripts) registered for path 'sd_scripts'\n",
            "Cloning into '/content/trainer/sd_scripts'...\n",
            "Submodule path 'sd_scripts': checked out '71e2c91330a9d866ec05cdd10584bbb962896a99'\n",
            "creating venv and installing requirements\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-10.2.0 sympy-1.13.1 torch-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1 typing-extensions-4.9.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting xformers==0.0.27\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from xformers==0.0.27) (1.26.3)\n",
            "Requirement already satisfied: torch==2.3.1 in ./venv/lib/python3.10/site-packages (from xformers==0.0.27) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (11.0.2.54)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (2.20.5)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (4.9.0)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (1.13.1)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->xformers==0.0.27) (12.1.105)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch==2.3.1->xformers==0.0.27) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch==2.3.1->xformers==0.0.27) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.27\n",
            "Obtaining file:///content/trainer/sd_scripts (from -r requirements.txt (line 42))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.25.0\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.36.2\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers[torch]==0.25.0\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.7.0.68\n",
            "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.7.0\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning==1.9.0\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.43.0\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prodigyopt==1.0\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Collecting lion-pytorch==0.0.6\n",
            "  Downloading lion_pytorch-0.0.6-py3-none-any.whl (4.2 kB)\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors==0.4.2\n",
            "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting altair==4.2.2\n",
            "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 KB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easygui==0.98.3\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toml==0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting voluptuous==0.13.1\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Collecting huggingface-hub==0.20.1\n",
            "  Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imagesize==1.4.1\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting rich==13.7.0\n",
            "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 KB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (1.26.3)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (2.3.1+cu121)\n",
            "Collecting tqdm>=4.27\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.19,>=0.14\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (3.13.1)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: Pillow in ./venv/lib/python3.10/site-packages (from diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (10.2.0)\n",
            "Collecting wcwidth>=0.2.5\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Collecting lightning-utilities>=0.4.2\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 KB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in ./venv/lib/python3.10/site-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.10/site-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.9.0)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting pandas>=0.18\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toolz\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from altair==4.2.2->-r requirements.txt (line 15)) (3.1.3)\n",
            "Collecting jsonschema>=3.0\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>1.9\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.48.2\n",
            "  Downloading grpcio-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=4.24.0,>=3.19.6\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (59.6.0)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.11.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.0/382.0 KB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Collecting referencing>=0.28.4\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Collecting attrs>=22.2.0\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 KB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 12)) (2.1.5)\n",
            "Collecting zipp>=3.20\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'opencv-python' candidate (version 4.7.0.68 at https://files.pythonhosted.org/packages/07/e2/405fd71f433960b0ce6a546536b05a26d85508df7eea98850784e10323e9/opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=3a00e12546e5578f6bb7ed408c37fcfea533d74e9691cfaf40926f6b43295577 (from https://pypi.org/simple/opencv-python/) (requires-python:>=3.6))\n",
            "Reason for being yanked: Deprecated, use 4.7.0.71\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: wcwidth, voluptuous, pytz, library, easygui, zipp, werkzeug, urllib3, tzdata, tqdm, toolz, toml, tensorboard-data-server, six, safetensors, rpds-py, regex, pyyaml, pygments, psutil, protobuf, propcache, prodigyopt, packaging, opencv-python, multidict, mdurl, markdown, imagesize, idna, grpcio, ftfy, frozenlist, entrypoints, einops, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, tensorboard, requests, referencing, python-dateutil, markdown-it-py, lightning-utilities, importlib-metadata, aiosignal, rich, pandas, jsonschema-specifications, huggingface-hub, aiohttp, torchmetrics, tokenizers, lion-pytorch, jsonschema, diffusers, bitsandbytes, accelerate, transformers, pytorch-lightning, altair\n",
            "  Running setup.py develop for library\n",
            "Successfully installed absl-py-2.1.0 accelerate-0.25.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 altair-4.2.2 async-timeout-5.0.1 attrs-24.2.0 bitsandbytes-0.43.0 certifi-2024.8.30 charset-normalizer-3.4.0 diffusers-0.25.0 easygui-0.98.3 einops-0.7.0 entrypoints-0.4 frozenlist-1.5.0 ftfy-6.1.1 grpcio-1.68.1 huggingface-hub-0.20.1 idna-3.10 imagesize-1.4.1 importlib-metadata-8.5.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 library-0.0.0 lightning-utilities-0.11.9 lion-pytorch-0.0.6 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 opencv-python-4.7.0.68 packaging-24.2 pandas-2.2.3 prodigyopt-1.0 propcache-0.2.1 protobuf-5.29.1 psutil-6.1.0 pygments-2.18.0 python-dateutil-2.9.0.post0 pytorch-lightning-1.9.0 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 regex-2024.11.6 requests-2.32.3 rich-13.7.0 rpds-py-0.22.3 safetensors-0.4.2 six-1.17.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tokenizers-0.15.2 toml-0.10.2 toolz-1.0.0 torchmetrics-1.6.0 tqdm-4.67.1 transformers-4.36.2 tzdata-2024.2 urllib3-2.2.3 voluptuous-0.13.1 wcwidth-0.2.13 werkzeug-3.1.3 yarl-1.18.3 zipp-3.21.0\n",
            "Processing /content/trainer/custom_scheduler\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Using legacy 'setup.py install' for LoraEasyCustomOptimizer, since package 'wheel' is not installed.\n",
            "Installing collected packages: LoraEasyCustomOptimizer\n",
            "  Running setup.py install for LoraEasyCustomOptimizer ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed LoraEasyCustomOptimizer-1.0.0\n",
            "Collecting starlette\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (2.32.3)\n",
            "Collecting dadaptation\n",
            "  Downloading dadaptation-3.2.tar.gz (13 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Collecting pycloudflared\n",
            "  Downloading pycloudflared-0.2.0-py3-none-any.whl (7.3 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting came-pytorch\n",
            "  Downloading came_pytorch-0.1.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting pytorch_optimizer==3.0.0\n",
            "  Downloading pytorch_optimizer-3.0.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lycoris-lora==3.0.0.post1\n",
            "  Downloading lycoris_lora-3.0.0.post1.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.10 in ./venv/lib/python3.10/site-packages (from pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (1.26.3)\n",
            "Requirement already satisfied: einops in ./venv/lib/python3.10/site-packages (from lycoris-lora==3.0.0.post1->-r ../requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: toml in ./venv/lib/python3.10/site-packages (from lycoris-lora==3.0.0.post1->-r ../requirements.txt (line 11)) (0.10.2)\n",
            "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from lycoris-lora==3.0.0.post1->-r ../requirements.txt (line 11)) (4.67.1)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]->-r ../requirements.txt (line 2)) (4.9.0)\n",
            "Collecting httptools>=0.6.3\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 KB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting watchfiles>=0.13\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 KB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]->-r ../requirements.txt (line 2)) (6.0.2)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->-r ../requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->-r ../requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->-r ../requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->-r ../requirements.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./venv/lib/python3.10/site-packages (from wandb->-r ../requirements.txt (line 5)) (5.29.1)\n",
            "Collecting sentry-sdk>=2.0.0\n",
            "  Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 KB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in ./venv/lib/python3.10/site-packages (from wandb->-r ../requirements.txt (line 5)) (6.1.0)\n",
            "Collecting platformdirs\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<3,>=2.6\n",
            "  Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 KB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from wandb->-r ../requirements.txt (line 5)) (59.6.0)\n",
            "Collecting tomli\n",
            "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Collecting exceptiongroup>=1.0.2\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in ./venv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r ../requirements.txt (line 5)) (1.17.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.0\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting pydantic-core==2.27.1\n",
            "  Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (10.3.2.106)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.3.1)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (2.3.1)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (3.13.1)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (2024.2.0)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.105)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (12.1.105)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10->pytorch_optimizer==3.0.0->-r ../requirements.txt (line 10)) (1.3.0)\n",
            "Using legacy 'setup.py install' for lycoris-lora, since package 'wheel' is not installed.\n",
            "Building wheels for collected packages: dadaptation\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dadaptation: filename=dadaptation-3.2-py3-none-any.whl size=23208 sha256=f4c657a731f596ef5f1dab5682bc3b39f779e9db41c01a57a4e1bbf4aa180594\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/03/6d/feba04df15ef39d9ac4e3504058ac2a88fb2ef9183ba92b111\n",
            "Successfully built dadaptation\n",
            "Installing collected packages: websockets, uvloop, typing-extensions, tomli, sniffio, smmap, setproctitle, sentry-sdk, scipy, python-dotenv, pyngrok, platformdirs, httptools, h11, exceptiongroup, docker-pycreds, dadaptation, click, annotated-types, uvicorn, pydantic-core, pycloudflared, gitdb, anyio, watchfiles, starlette, pydantic, gitpython, wandb, pytorch_optimizer, lycoris-lora, came-pytorch\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Running setup.py install for lycoris-lora ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 came-pytorch-0.1.3 click-8.1.7 dadaptation-3.2 docker-pycreds-0.4.0 exceptiongroup-1.2.2 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httptools-0.6.4 lycoris-lora-3.0.0.post1 platformdirs-4.3.6 pycloudflared-0.2.0 pydantic-2.10.3 pydantic-core-2.27.1 pyngrok-7.2.1 python-dotenv-1.0.1 pytorch_optimizer-3.0.0 scipy-1.14.1 sentry-sdk-2.19.0 setproctitle-1.3.4 smmap-5.0.1 sniffio-1.3.1 starlette-0.41.3 tomli-2.2.1 typing-extensions-4.12.2 uvicorn-0.32.1 uvloop-0.21.0 wandb-0.19.0 watchfiles-1.0.0 websockets-14.1\n",
            "completed installing\n",
            "Installation complete!\n",
            "Downloading tagger script that allows v3 taggers...\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "988e69|\u001b[1;32mOK\u001b[0m  |   1.3MiB/s|//content/trainer/sd_scripts/finetune/tag_images_by_wd14_tagger.py\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Fixing sd_scripts logging issue on colab...\n",
            "Found existing installation: rich 13.7.0\n",
            "Uninstalling rich-13.7.0:\n",
            "  Would remove:\n",
            "    /content/trainer/sd_scripts/venv/lib/python3.10/site-packages/rich-13.7.0.dist-info/*\n",
            "    /content/trainer/sd_scripts/venv/lib/python3.10/site-packages/rich/*\n",
            "Proceed (Y/n)?   Successfully uninstalled rich-13.7.0\n",
            "Finished installation!\n"
          ]
        }
      ],
      "source": [
        "# @title ## 1. Install the trainer ![doro](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro.png)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "root_path = Path(\"/content\")\n",
        "trainer_dir = root_path.joinpath(\"trainer\")\n",
        "\n",
        "venv_pip = trainer_dir.joinpath(\"sd_scripts/venv/bin/pip\")\n",
        "venv_python = trainer_dir.joinpath(\"sd_scripts/venv/bin/python\")\n",
        "\n",
        "# @markdown Execute the cell to install the trainer\n",
        "\n",
        "installed_dependencies = False\n",
        "first_step_done = False\n",
        "\n",
        "def install_trainer():\n",
        "  global installed_dependencies, first_step_done\n",
        "\n",
        "  print(\"Installing trainer...\")\n",
        "  !apt -y update -qq\n",
        "  !apt install -y python3.10-venv aria2 -qq\n",
        "\n",
        "  installed_dependencies = True\n",
        "\n",
        "  !git clone https://github.com/derrian-distro/LoRA_Easy_Training_scripts_Backend {trainer_dir}\n",
        "\n",
        "  !chmod 755 /content/trainer/colab_install.sh\n",
        "  os.chdir(trainer_dir)\n",
        "  !./colab_install.sh\n",
        "\n",
        "  os.chdir(root_path)\n",
        "\n",
        "  first_step_done = True\n",
        "  print(\"Installation complete!\")\n",
        "\n",
        "def download_custom_wd_tagger():\n",
        "  global wd_path\n",
        "\n",
        "  wd_path = trainer_dir.joinpath(\"sd_scripts/finetune/tag_images_by_wd14_tagger.py\")\n",
        "\n",
        "  print(\"Downloading tagger script that allows v3 taggers...\")\n",
        "  !rm \"{wd_path}\"\n",
        "  !aria2c \"https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/main/custom/tag_images_by_wd14_tagger.py\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{wd_path}\"\n",
        "\n",
        "def fix_scripts_logging():\n",
        "  print(\"Fixing sd_scripts logging issue on colab...\")\n",
        "  !yes | {venv_pip} uninstall rich\n",
        "\n",
        "def main():\n",
        "  install_trainer()\n",
        "  download_custom_wd_tagger()\n",
        "  fix_scripts_logging()\n",
        "  print(\"Finished installation!\")\n",
        "\n",
        "try:\n",
        "  main()\n",
        "except Exception as e:\n",
        "  print(f\"Error intalling the trainer!\\n{e}\")\n",
        "  first_step_done = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "oS4dJqXoiyC5",
        "outputId": "69c5587a-5ad0-4a10-a9d2-afcfdbff89ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up directories...\n",
            "Mounted at /content/drive\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# @title ## 2. Setup the directories ![doro diamond](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_diamond.png)\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "if not globals().get(\"first_step_done\"):\n",
        "  root_path = Path(\"/content\")\n",
        "  trainer_dir = root_path.joinpath(\"trainer\")\n",
        "\n",
        "drive_dir = root_path.joinpath(\"drive/MyDrive\")\n",
        "pretrained_model_dir = root_path.joinpath(\"pretrained_model\")\n",
        "vae_dir = root_path.joinpath(\"vae\")\n",
        "tagger_models_dir = root_path.joinpath(\"tagger_models\")\n",
        "\n",
        "# @markdown The base path for your project. Make sure it can be used as a folder name\n",
        "project_path = \"Loras/nfkkpiro\" # @param {type: \"string\"}\n",
        "# @markdown Specify the name for the directories. If you have multiple datasets, separate each with a comma `(,)` like this: **dataset1, dataset2, ...**\n",
        "\n",
        "# @markdown The directory where the results of the training will be stored.\n",
        "output_dir_name = \"output\" # @param {type: \"string\"}\n",
        "# @markdown The directory where your dataset(s) will be located.\n",
        "dataset_dir_name = \"dataset\" # @param {type: \"string\"}\n",
        "# @markdown Use Drive to store all the files and directories\n",
        "use_drive = True # @param {type: \"boolean\"}\n",
        "\n",
        "project_path = project_path.replace(\" \", \"_\")\n",
        "output_dir_name = output_dir_name.replace(\" \", \"_\")\n",
        "\n",
        "second_step_done = False\n",
        "\n",
        "def is_valid_folder_name(folder_name: str) -> bool:\n",
        "  invalid_characters = '<>:\"/\\|?*'\n",
        "\n",
        "  if any(char in invalid_characters for char in folder_name):\n",
        "    return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def mount_drive_dir() -> Path:\n",
        "  base_dir = root_path.joinpath(project_path)\n",
        "\n",
        "  if use_drive:\n",
        "    if not Path(drive_dir).exists():\n",
        "      drive.mount(Path(drive_dir).parent.as_posix())\n",
        "    base_dir = drive_dir.joinpath(project_path)\n",
        "\n",
        "  return base_dir\n",
        "\n",
        "def make_directories():\n",
        "  mount_drive = mount_drive_dir()\n",
        "  output_dir = mount_drive.joinpath(output_dir_name)\n",
        "\n",
        "  if not Path(mount_drive).exists():\n",
        "    Path(mount_drive).mkdir(exist_ok=True)\n",
        "\n",
        "  for dir in [pretrained_model_dir, vae_dir, output_dir, tagger_models_dir]:\n",
        "    Path(dir).mkdir(exist_ok=True)\n",
        "\n",
        "  for dataset_m_dir in dataset_dir_name.replace(\" \", \"\").split(','):\n",
        "    if is_valid_folder_name(dataset_m_dir):\n",
        "      Path(mount_drive.joinpath(dataset_m_dir)).mkdir(exist_ok=True)\n",
        "    else:\n",
        "      print(f\"{dataset_m_dir} is not a valid name for a folder\")\n",
        "      return\n",
        "\n",
        "def main():\n",
        "  for name in [project_path, output_dir_name]:\n",
        "      if not is_valid_folder_name(name.replace(\"/\", \"\") if project_path == name else name):\n",
        "        print(f\"{name} is not a valid name for a folder\")\n",
        "        return\n",
        "\n",
        "  print(\"Setting up directories...\")\n",
        "  make_directories()\n",
        "  print(\"Done!\")\n",
        "\n",
        "try:\n",
        "  main()\n",
        "  second_step_done = True\n",
        "except Exception as e:\n",
        "  print(f\"Error setting up the directories!\\n{e}\")\n",
        "  second_step_done = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0_HNDa7Zdei",
        "cellView": "form",
        "outputId": "38fecd47-ba34-40b6-b734-6bdca169afcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model from https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0/resolve/main/Illustrious-XL-v0.1.safetensors...\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title ## 3. Download the base model and/or VAE used for training ![doro fubuki](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_fubuki.png)\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "model_url = \"\"\n",
        "vae_url = \"\"\n",
        "\n",
        "# @markdown Default models are provided here for training. If you want to use another one, introduce the URL in the input below. The link must be pointing to either Civitai or Hugging Face and have the correct format. You can check how to get the correct link [here](https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#how-to-get-the-link-for-custom-modelvae).\n",
        "training_model = \"(XL) Illustrious v0.1\" # @param [\"(XL) PonyDiffusion v6\", \"(XL) NoobAI Epsilon v1.0\", \"(XL) Illustrious v0.1\", \"(XL) Animagine 3.1\", \"(XL) SDXL 1.0\", \"(1.5) anime-full-final-pruned (Most used on Anime LoRAs)\", \"(1.5) AnyLora\", \"(1.5) SD 1.5\"]\n",
        "custom_training_model = \"\" # @param {type: \"string\"}\n",
        "# @markdown The name you want to give to the downloaded model file, if not specified default ones will be used.\n",
        "model_name = \"\" # @param {type: \"string\"}\n",
        "# @markdown VAE used for training. It's not needed for 1.5 nor XL, but it's recommended to use the SDXL base VAE for XL training. If you want to use a custom one, introduce the URL in the input below.\n",
        "vae = \"SDXL VAE\" # @param [\"SDXL VAE\", \"None\"]\n",
        "custom_vae = \"\" # @param {type: \"string\"}\n",
        "# @markdown The name you want to give to the downloaded VAE file, if not specified default ones will be used.\n",
        "vae_name = \"\" # @param {type: \"string\"}\n",
        "# @markdown Introduce your [Civitai API Token](https://civitai.com/user/account) or [HuggingFace Access Token](https://huggingface.co/settings/tokens) if the authentication fails while downloading the model and/or VAE.\n",
        "api_token = \"\" # @param {type: \"string\"}\n",
        "# @markdown You can optionally download the model and/or VAE on your drive so you don't need to download them again in the next session. You only would need to specify their path on the UI for the next time you want to use them.\n",
        "download_in_drive = False # @param {type: \"boolean\"}\n",
        "\n",
        "thrid_step_done = False\n",
        "\n",
        "if custom_training_model:\n",
        "  model_url = custom_training_model\n",
        "elif \"Pony\" in training_model:\n",
        "  model_url = \"https://huggingface.co/AstraliteHeart/pony-diffusion-v6/resolve/main/v6.safetensors\"\n",
        "elif \"Animagine\" in training_model:\n",
        "  model_url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\"\n",
        "elif \"SDXL\" in training_model:\n",
        "  model_url = \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\"\n",
        "elif \"anime\" in training_model:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
        "elif \"Any\" in training_model:\n",
        "  model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.safetensors\"\n",
        "elif \"SD 1.5\" in training_model:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
        "elif \"Illustrious\" in training_model:\n",
        "  model_url = \"https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0/resolve/main/Illustrious-XL-v0.1.safetensors\"\n",
        "elif \"NoobAI\" in training_model:\n",
        "  model_url = \"https://huggingface.co/Laxhar/noobai-XL-1.0/resolve/main/NoobAI-XL-v1.0.safetensors\"\n",
        "\n",
        "if custom_vae:\n",
        "  vae_url = custom_vae\n",
        "elif \"SDXL\" in vae:\n",
        "  vae_url = \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\"\n",
        "\n",
        "model_file = \"\"\n",
        "vae_file = \"\"\n",
        "\n",
        "header = \"\"\n",
        "\n",
        "if not \"installed_dependencies\" in globals():\n",
        "  print(\"Installing missing dependency...\")\n",
        "  !apt -y update -qq\n",
        "  !apt install -y aria2 -qq\n",
        "  globals().setdefault(\"installed_dependencies\", True)\n",
        "\n",
        "def download_model():\n",
        "  global model_file, model_url, pretrained_model_dir\n",
        "\n",
        "  if re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\", model_url):\n",
        "    model_url = model_url.replace(\"blob\", \"resolve\")\n",
        "  elif re.search(r\"https:\\/\\/civitai\\.com\\/models\\/\\d+\", model_url):\n",
        "    if m := re.search(r\"modelVersionId=(\\d+)\", model_url):\n",
        "      model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "  elif not re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\", model_url) and not re.search(r\"https:\\/\\/civitai\\.com\\/api\\/download\\/models\\/(\\d+)\", model_url):\n",
        "    print(\"Invalid model download URL!\\nCheck how to get the correct link in https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#how-to-get-the-link-for-custom-modelvae\")\n",
        "    return\n",
        "\n",
        "  if \"civitai.com\" in model_url and api_token and not \"hf\" in api_token:\n",
        "    model_url = f\"{model_url}&token={api_token}\" if \"?\" in model_url else f\"{model_url}?token={api_token}\"\n",
        "  elif \"huggingface.co\" in model_url and api_token:\n",
        "    header = f\"Authorization: Bearer {api_token}\"\n",
        "\n",
        "  stripped_model_url = model_url.strip()\n",
        "\n",
        "  if download_in_drive:\n",
        "    pretrained_model_dir = Path(drive_dir).joinpath(\"Downloaded_models\")\n",
        "\n",
        "    if not Path(pretrained_model_dir).exists():\n",
        "      Path(pretrained_model_dir).mkdir(exist_ok=True)\n",
        "\n",
        "  if model_name:\n",
        "    validated_name = model_name.translate(str.maketrans('', '', '\\\\/:*?\"<>|'))\n",
        "\n",
        "    if not validated_name.endswith((\".ckpt\", \".safetensors\")):\n",
        "      model_file = pretrained_model_dir.joinpath(f\"{validated_name}.safetensors\")\n",
        "    else:\n",
        "      model_file = pretrained_model_dir.joinpath(validated_name)\n",
        "  elif stripped_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "    model_file = pretrained_model_dir.joinpath(stripped_model_url[stripped_model_url.rfind('/'):].replace(\"/\", \"\"))\n",
        "  else:\n",
        "    model_file = pretrained_model_dir.joinpath(\"downloaded_model.safetensors\")\n",
        "    if Path(model_file).exists() and not download_in_drive:\n",
        "      !rm \"{model_file}\"\n",
        "\n",
        "  print(f\"Downloading model from {model_url}...\")\n",
        "  !aria2c \"{model_url}\" --console-log-level=warn --header=\"{header}\" -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "def download_vae():\n",
        "  global vae_file, vae_url, vae_dir\n",
        "\n",
        "  if not vae == \"None\":\n",
        "    if re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\", vae_url):\n",
        "      vae_url = vae_url.replace(\"blob\", \"resolve\")\n",
        "    elif re.search(r\"https:\\/\\/civitai\\.com\\/models\\/\\d+\", vae_url):\n",
        "      if m := re.search(r\"modelVersionId=(\\d+)\", vae_url):\n",
        "        vae_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "    elif not re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\", vae_url) and not re.search(r\"https:\\/\\/civitai\\.com\\/api\\/download\\/models\\/(\\d+)\", vae_url):\n",
        "      print(\"Invalid VAE download URL!\\nCheck how to get the correct link in https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#how-to-get-the-link-for-custom-modelvae\")\n",
        "      return\n",
        "\n",
        "    if \"civitai.com\" in vae_url and api_token and not \"hf\" in api_token:\n",
        "      vae_url = f\"{vae_url}&token={api_token}\" if \"?\" in vae_url else f\"{vae_url}?token={api_token}\"\n",
        "    elif \"huggingface.co\" in vae_url and api_token:\n",
        "      header = f\"Authorization: Bearer {api_token}\"\n",
        "\n",
        "    stripped_model_vae = vae_url.strip()\n",
        "\n",
        "    if download_in_drive:\n",
        "      vae_dir = Path(drive_dir).joinpath(\"Downloaded_VAEs\")\n",
        "\n",
        "      if not Path(vae_dir).exists():\n",
        "        Path(vae_dir).mkdir(exist_ok=True)\n",
        "\n",
        "    if vae_name:\n",
        "      validated_name = vae_name.translate(str.maketrans('', '', '\\\\/:*?\"<>|'))\n",
        "\n",
        "      if not validated_name.endswith((\".ckpt\", \".safetensors\")):\n",
        "        vae_file = vae_dir.joinpath(f\"{validated_name}.safetensors\")\n",
        "      else:\n",
        "        vae_file = vae_dir.joinpath(validated_name)\n",
        "    elif stripped_model_vae.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "      vae_file = vae_dir.joinpath(stripped_model_vae[stripped_model_vae.rfind('/'):].replace(\"/\", \"\"))\n",
        "    else:\n",
        "      vae_file = vae_dir.joinpath(\"downloaded_vae.safetensors\")\n",
        "      if Path(vae_file).exists() and not download_in_drive:\n",
        "        !rm \"{vae_file}\"\n",
        "\n",
        "    print(f\"Downloading vae from {vae_url}...\")\n",
        "    !aria2c \"{vae_url}\" --console-log-level=warn --header=\"{header}\" -c -s 16 -x 16 -k 10M -d / -o \"{vae_file}\"\n",
        "  else:\n",
        "    vae_file = \"\"\n",
        "\n",
        "def main():\n",
        "  if not globals().get(\"second_step_done\"):\n",
        "    print(\"You have to run the 2nd step first!\")\n",
        "    return\n",
        "\n",
        "  if download_in_drive and not use_drive:\n",
        "    print(\"You are trying to download the model and/or VAE in your drive but you didn't mount it. Please select the 'use_drive' option in 2nd step.\")\n",
        "    return\n",
        "\n",
        "  download_model()\n",
        "  download_vae()\n",
        "\n",
        "try:\n",
        "  main()\n",
        "  thrid_step_done = True\n",
        "except Exception as e:\n",
        "  print(f\"Failed to download the models\\n{e}\")\n",
        "  thrid_step_done = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "66XBK6B_iSYj"
      },
      "outputs": [],
      "source": [
        "# @title ## 4. Upload your dataset ![doro shifty](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_shifty.png)\n",
        "import re\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown ### Unzip the dataset\n",
        "# @markdown If you have a dataset in a zip file, you can specify the path to it below. This will extract the dataset into the dataset directory specified in step 2. It supports downloading the zip from **HuggingFace**. To get the correct link you only need to follow the steps [for models/VAEs](https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#from-huggingface) but applying them to the zip file.\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/dataset.zip\" # @param {type: \"string\"}\n",
        "# @markdown Specify the name of your dataset directory. If it doesn't exist, it will be created. If you have multiple dataset directories, extract each zip file into its respective dataset directory.\n",
        "extract_to_dataset_dir = \"dataset\" # @param {type: \"string\"}\n",
        "# @markdown Provide a [HuggingFace Access Token](https://huggingface.co/settings/tokens) if your dataset is in a private repository.\n",
        "hf_token = \"\" # @param {type: \"string\"}\n",
        "\n",
        "if not \"installed_dependencies\" in globals():\n",
        "  print(\"Installing missing dependency...\")\n",
        "  !apt -y update -qq\n",
        "  !apt install -y aria2 -qq\n",
        "  globals().setdefault(\"installed_dependencies\", True)\n",
        "\n",
        "def extract_dataset():\n",
        "  global zip_path\n",
        "  is_from_hf = False\n",
        "\n",
        "  if not globals().get(\"second_step_done\"):\n",
        "    print(\"You didn't complete the second step!\")\n",
        "    return\n",
        "\n",
        "  if zip_path.startswith(\"https://huggingface.co/\"):\n",
        "    is_from_hf = True\n",
        "\n",
        "  if not Path(zip_path).exists() and not is_from_hf:\n",
        "    print(\"The path of the zip doesn't exists!\")\n",
        "    return\n",
        "\n",
        "  if \"drive/MyDrive\" in zip_path and not Path(drive_dir).exists():\n",
        "    print(\"Your trying to access drive but you didn't mount it!\")\n",
        "    return\n",
        "\n",
        "  dataset_dir = root_path.joinpath(project_path, extract_to_dataset_dir)\n",
        "  if Path(drive_dir).exists():\n",
        "    dataset_dir = drive_dir.joinpath(project_path, extract_to_dataset_dir)\n",
        "\n",
        "  if not Path(dataset_dir).exists():\n",
        "    Path(dataset_dir).mkdir(exist_ok=True)\n",
        "    print(f\"Created dataset directory on new location because it didn't exist before: {dataset_dir}\")\n",
        "\n",
        "  if is_from_hf and re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\\.zip\", zip_path):\n",
        "    print(\"Zip file from HuggingFace detected, attempting to download...\")\n",
        "\n",
        "    if \"blob\" in zip_path:\n",
        "      zip_path = zip_path.replace(\"blob\", \"resolve\")\n",
        "    header = f\"Authorization: Bearer {hf_token}\" if hf_token else \"\"\n",
        "\n",
        "    !aria2c \"{zip_path}\" --console-log-level=warn --header=\"{header}\" -c -s 16 -x 16 -k 10M -d / -o \"/content/dataset.zip\"\n",
        "    zip_path = \"/content/dataset.zip\"\n",
        "  elif is_from_hf and not re.search(r\"https:\\/\\/huggingface\\.co\\/.*(?:resolve|blob).*\\.zip\", zip_path):\n",
        "    print(\"Invalid URL provided for downloading the zip file.\")\n",
        "    return\n",
        "\n",
        "  print(\"Extracting dataset...\")\n",
        "\n",
        "  with zipfile.ZipFile(zip_path, 'r') as f:\n",
        "    f.extractall(dataset_dir)\n",
        "\n",
        "  print(f\"Dataset extracted in {dataset_dir}\")\n",
        "\n",
        "  if is_from_hf:\n",
        "    print(\"Removing temporary zip file...\")\n",
        "    !rm \"{zip_path}\"\n",
        "    print(\"Done!\")\n",
        "\n",
        "extract_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J86M4s3ohUYv"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Tag your images ![doro syuen](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_syuen.png)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown As the name suggests, this is the type of tagging you want for your dataset.\n",
        "method = \"Anime\" # @param [\"Anime\", \"Photorealistic\"]\n",
        "# @markdown `(Only applies to Anime method)` The default model used for tagging is `SmilingWolf/wd-eva02-large-tagger-v3`. I find it more accurate than other taggers, but if you have experience, you can use another one and tweak the parameters. If you don't, the default configuration should be fine.\n",
        "model = \"SmilingWolf/wd-eva02-large-tagger-v3\" # @param [\"SmilingWolf/wd-eva02-large-tagger-v3\", \"SmilingWolf/wd-vit-large-tagger-v3\", \"SmilingWolf/wd-swinv2-tagger-v3\", \"SmilingWolf/wd-vit-tagger-v3\", \"SmilingWolf/wd-convnext-tagger-v3\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-moat-tagger-v2\", \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "# @markdown The directory name of the dataset you want to tag. You can specify another directory when the previous one is fully tagged, in case you have more than one dataset.\n",
        "dataset_dir_name = \"dataset\" # @param {type: \"string\"}\n",
        "# @markdown The type of file to save your captions.\n",
        "file_extension = \".txt\" # @param [\".txt\", \".caption\"]\n",
        "# @markdown `(Only applies to Anime method)` Specify the tags that you don't want the autotagger to use. Separate each one with a comma `(,)` like this: **1girl, solo, standing, ...**\n",
        "blacklisted_tags = \"\" # @param {type: \"string\"}\n",
        "# @markdown `(Only applies to Anime method)` Specify the minimum confidence level required for assigning a tag to the image. A lower threshold results in more tags being assigned. The recommended default value for v2 taggers is 0.35 and for v3 is 0.25.\n",
        "threshold = 0.25 # @param {type: \"slider\", min:0.0, max: 1.0, step:0.01}\n",
        "# @markdown `(Only applies to Photorealistic method)` Specify the minimum number of words (also known as tokens) to include in the captions.\n",
        "caption_min = 10 # @param {type: \"number\"}\n",
        "# @markdown `(Only applies to Photorealistic method)` Specify the maximum number of words (also known as tokens) to include in the captions.\n",
        "caption_max = 75 # @param {type: \"number\"}\n",
        "\n",
        "blacklisted_tags = blacklisted_tags.replace(\" \", \"\")\n",
        "\n",
        "def caption_images():\n",
        "  global use_onnx_runtime\n",
        "\n",
        "  if not globals().get(\"second_step_done\"):\n",
        "    print(\"You didn't complete the second step!\")\n",
        "    return\n",
        "\n",
        "  dataset_dir = root_path.joinpath(project_path, dataset_dir_name)\n",
        "  if Path(drive_dir).exists():\n",
        "    dataset_dir = drive_dir.joinpath(project_path, dataset_dir_name)\n",
        "\n",
        "  sd_scripts = trainer_dir.joinpath(\"sd_scripts\")\n",
        "  if not globals().get(\"first_step_done\"):\n",
        "    print(\"Please run the step 1 first.\")\n",
        "    return\n",
        "\n",
        "  if not globals().get(\"tagger_dependencies\"):\n",
        "    print(\"Installing missing dependencies...\")\n",
        "    !{venv_pip} install fairscale==0.4.13 timm==0.6.12\n",
        "    !{venv_pip} install onnxruntime-gpu==1.17.1 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "    globals().setdefault(\"tagger_dependencies\", True)\n",
        "\n",
        "  batch_size = 8 if \"v3\" in model or \"swinv2\" in model else 1\n",
        "\n",
        "  model_dir = tagger_models_dir.joinpath(model.split(\"/\")[-1])\n",
        "\n",
        "  print(\"Tagging images\")\n",
        "\n",
        "  if method == \"Anime\":\n",
        "    !{venv_python} {wd_path} \\\n",
        "      {dataset_dir} \\\n",
        "      --repo_id={model} \\\n",
        "      --model_dir={model_dir} \\\n",
        "      --thresh={threshold} \\\n",
        "      --batch_size={batch_size} \\\n",
        "      --max_data_loader_n_workers=2 \\\n",
        "      --caption_extension={file_extension} \\\n",
        "      --undesired_tags={blacklisted_tags} \\\n",
        "      --remove_underscore \\\n",
        "      --onnx\n",
        "  else:\n",
        "    os.chdir(sd_scripts)\n",
        "    !{venv_python} finetune/make_captions.py \\\n",
        "      {dataset_dir} \\\n",
        "      --beam_search \\\n",
        "      --max_data_loader_n_workers=2 \\\n",
        "      --batch_size=8 \\\n",
        "      --min_length={caption_min} \\\n",
        "      --max_length={caption_max} \\\n",
        "      --caption_extension=.txt\n",
        "    os.chdir(root_path)\n",
        "\n",
        "  print(\"Tagging complete!\")\n",
        "\n",
        "caption_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PC5JsouHTr26"
      },
      "outputs": [],
      "source": [
        "# @title ## 5. Start the training ![doro cinderella](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_cinderella.png)\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown Execute this cell to obtain the paths. Input these paths into the UI to start the training.\n",
        "\n",
        "def print_paths():\n",
        "  if not globals().get(\"second_step_done\"):\n",
        "    print(\"You didn't complete the second step!\")\n",
        "    return\n",
        "\n",
        "  dataset_dirs = []\n",
        "  project_base_dir = root_path.joinpath(project_path)\n",
        "  if globals().get(\"use_drive\"):\n",
        "    project_base_dir = drive_dir.joinpath(project_path)\n",
        "\n",
        "  for id, p_dataset_m_dir in enumerate(dataset_dir_name.replace(\" \", \"\").split(',')):\n",
        "    dataset_dirs.append(f\"Dataset directory {id + 1}: {project_base_dir.joinpath(p_dataset_m_dir)}\")\n",
        "\n",
        "  model_path = model_file or \"None or you didn't run the cell to download it either because you forgot or because you have the model in drive\"\n",
        "  vae_path = vae_file or \"None or you didn't run the cell to download it either because you forgot or because you have the VAE in drive\"\n",
        "  output_path = project_base_dir.joinpath(output_dir_name)\n",
        "\n",
        "  print(\"Dataset paths:\\n  {0}\\nModel path: {1}\\nVAE path: {2}\\nOutput path: {3}\\nConfig file path: {4}\\nTags file path: {4}\".format('\\n  '.join(dataset_dirs), model_path.as_posix().replace(\" \", \"\"), vae_path, output_path, \"It's saved locally on your machine\"))\n",
        "\n",
        "print_paths()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "80gDArpjBLk-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown Running this cell will create a tunnel that allows you to connect from your local UI so you can send the training settings to colab. If you don't have it installed, please install it [from here](https://github.com/derrian-distro/LoRA_Easy_Training_Scripts). Read the [instructions for installation](https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#how-to-install-the-ui). Once you launch the UI, set up your training parameters, copy the given URL into your interface, and click \"Start training\".\n",
        "\n",
        "# @markdown `(Optional)` Ngrok is an alternative method, and you need a token that you can obtain from [Ngrok's dashboard](https://dashboard.ngrok.com/get-started/your-authtoken). I recommend using it only if you want, have experience, or if the default tunnel provider is down. [How to obtain Ngrok token](https://github.com/Jelosus2/LoRA_Easy_Training_Colab?tab=readme-ov-file#how-to-obtain-the-ngrok-token)\n",
        "\n",
        "use_ngrok = False # @param {type: \"boolean\"}\n",
        "ngrok_token = \"\" # @param {type: \"string\"}\n",
        "\n",
        "fifth_step_done = False\n",
        "\n",
        "def init_tunnel():\n",
        "  global fifth_step_done\n",
        "\n",
        "  if not globals().get(\"first_step_done\"):\n",
        "    print(\"Please run the 1st step first.\")\n",
        "    return\n",
        "\n",
        "  if not globals().get(\"second_step_done\"):\n",
        "    print(\"You didn't complete the second step!\")\n",
        "    return\n",
        "\n",
        "  config_file = trainer_dir.joinpath(\"config.json\")\n",
        "\n",
        "  if use_ngrok:\n",
        "    if not ngrok_token:\n",
        "      print(\"The ngrok token must not be empty!\")\n",
        "      return\n",
        "\n",
        "    with open(config_file, 'r') as config:\n",
        "      data = json.load(config)\n",
        "\n",
        "    data[\"remote_mode\"] = \"ngrok\"\n",
        "    data[\"ngrok_token\"] = ngrok_token\n",
        "\n",
        "    with open(config_file, 'w') as config:\n",
        "      json.dump(data, config, indent=2)\n",
        "  else:\n",
        "    with open(config_file, 'r') as config:\n",
        "      data = json.load(config)\n",
        "\n",
        "    if data[\"remote_mode\"] == \"ngrok\":\n",
        "      data[\"remote_mode\"] = \"cloudflared\"\n",
        "      data[\"ngrok_token\"] = \"\"\n",
        "\n",
        "      with open(config_file, 'w') as config:\n",
        "        json.dump(data, config, indent=2)\n",
        "\n",
        "  os.chdir(trainer_dir)\n",
        "  !chmod 755 run.sh\n",
        "  !./run.sh\n",
        "  os.chdir(root_path)\n",
        "\n",
        "  fifth_step_done = True\n",
        "\n",
        "init_tunnel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ufU4_DUl2Rzv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown Run this cell to start the training\n",
        "\n",
        "# @markdown Are you training on sdxl?\n",
        "sdxl = True # @param {type: \"boolean\"}\n",
        "\n",
        "def start_training(is_sdxl: bool):\n",
        "  if not globals().get(\"fifth_step_done\"):\n",
        "    print(\"Run the cell above this one first!\")\n",
        "    return\n",
        "\n",
        "  os.chdir(trainer_dir)\n",
        "\n",
        "  config = Path(\"runtime_store/config.toml\").resolve()\n",
        "  dataset = Path(\"runtime_store/dataset.toml\").resolve()\n",
        "\n",
        "  if not Path(config).exists() and not Path(dataset).exists():\n",
        "    print(\"The required files were not generated while running the above cell, please check again!\")\n",
        "    return\n",
        "\n",
        "  sd_scripts = Path(\"sd_scripts\").resolve()\n",
        "  training_network = \"sdxl_train_network.py\" if is_sdxl else \"train_network.py\"\n",
        "\n",
        "  !{venv_python} {sd_scripts.joinpath(training_network)} \\\n",
        "    --config_file={config} \\\n",
        "    --dataset_config={dataset}\n",
        "\n",
        "  os.chdir(root_path)\n",
        "\n",
        "start_training(sdxl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Utils ![doro anachiro](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_anachiro.png)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown ### LoRA Resizer ![doro grave](https://raw.githubusercontent.com/Jelosus2/Lora_Easy_Training_Colab/refs/heads/main/assets/doro_grave.png)\n",
        "\n",
        "# @markdown The path pointing to the LoRA file you want to resize.\n",
        "lora = \"\" # @param {type: \"string\"}\n",
        "# @markdown `(Optional)` The path of the directory where the resized LoRA will be saved. If not specified the parent directory of the loaded LoRA will be used.\n",
        "output_dir = \"\" # @param {type: \"string\"}\n",
        "# @markdown `(Optional)` The name for the resized LoRA file. If not specified the name of the loaded LoRA will be used appending **_resized** to it.\n",
        "output_name = \"\" # @param {type: \"string\"}\n",
        "# @markdown The precision for saving the resized LoRA. `fp16` is the usual precision to use. **Don't touch unless you know what you are doing!**\n",
        "save_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"float\"]\n",
        "# @markdown The new dimensions, aka dim, for the LoRA.\n",
        "new_dim = 4 # @param {type: \"number\"}\n",
        "# @markdown `(LoCon-like networks only)` The new conv dimensions, aka conv dim, for the LoRA. Only use on networks that are trained with conv. For example: **LoCon, LyCORIS, LoHa, Lokr, etc**. Keep the value less than 1 to omit it's usage.\n",
        "new_conv_dim = 0 # @param {type: \"number\"}\n",
        "# @markdown Enables/disables the usage of `dynamic_method` and `dynamic_param`. **Don't touch unless you know what you are doing!**\n",
        "use_dynamic = False # @param {type: \"boolean\"}\n",
        "# @markdown Method used to calculate the resize. `sv_fro` is the usual method to use.\n",
        "dynamic_method = \"sv_fro\" # @param [\"sv_fro\", \"sv_ratio\", \"sv_cumulative\"]\n",
        "# @markdown Value used by the `dynamic_method` to calculate the resize.\n",
        "dynamic_param = 0.9700 # @param {type: \"number\"}\n",
        "# @markdown Use the GPU resources to resize the LoRA. If disabled it will use the CPU which is **not recommended!**\n",
        "use_gpu = True # @param {type: \"boolean\"}\n",
        "# @markdown Prints in the console the information about the resizing when the process finishes.\n",
        "verbose_printing = False # @param {type: \"boolean\"}\n",
        "# @markdown `(LoCon-like networks only)` Removes the conv dim layers from the LoRA. Only use on networks that are trained with conv. For example: **LoCon, LyCORIS, LoHa, Lokr, etc. Don't touch unless you know what you are doing!**\n",
        "remove_conv_dims = False # @param {type: \"boolean\"}\n",
        "# @markdown Removes the linear dim layers (which is what is trained usually in a LoRA) from the LoRA. **Don't touch unless you know what you are doing!**\n",
        "remove_linear_dims = False # @param {type: \"boolean\"}\n",
        "\n",
        "def validate() -> tuple[bool, bool]:\n",
        "  global output_dir, output_name\n",
        "\n",
        "  failed = False\n",
        "  use_conv = True\n",
        "  if not globals().get(\"first_step_done\"):\n",
        "    print(\"Please run the 1st step first.\")\n",
        "    failed = True\n",
        "\n",
        "  if not Path(lora).is_file() or Path(lora).suffix not in [\".ckpt\", \".safetensors\"]:\n",
        "    print(\"The path to the LoRA file is invalid.\")\n",
        "    failed = True\n",
        "\n",
        "  if not Path(output_dir).is_dir() or not output_dir:\n",
        "    output_dir = Path(output_dir).parent if output_dir else Path(lora).parent\n",
        "    if not output_dir.is_dir():\n",
        "      print(\"The path to the output folder is invalid, or not a folder\")\n",
        "      failed = True\n",
        "    output_dir = output_dir.as_posix()\n",
        "\n",
        "  if not output_name:\n",
        "    output_name = f\"{Path(lora).name.split('.')[0]}_resized\"\n",
        "  else:\n",
        "    output_name = output_name.split(\".\")[0]\n",
        "\n",
        "  if Path(output_dir).joinpath(f\"{output_name}.safetensors\").exists():\n",
        "    idx = 1\n",
        "    temp_name = output_name\n",
        "    while Path(output_dir).joinpath(f\"{output_name}.safetensors\").exists():\n",
        "      output_name = f\"{temp_name}_{idx}\"\n",
        "      idx += 1\n",
        "\n",
        "    print(f\"Duplicated file in the output directory, file name changed to {output_name}\")\n",
        "\n",
        "  if new_dim < 1:\n",
        "    print(\"The new dim must be 1 or greater\")\n",
        "    failed = True\n",
        "\n",
        "  if new_conv_dim < 1:\n",
        "    print(\"Skipping setting new conv dim, using new dim only\")\n",
        "    use_conv = False\n",
        "\n",
        "  if use_dynamic and dynamic_param <= 0:\n",
        "    print(\"The dynamic param must be greater than 0\")\n",
        "    failed = True\n",
        "\n",
        "  return failed, use_conv\n",
        "\n",
        "def resize_lora(use_conv: bool):\n",
        "  output_file = Path(output_dir).joinpath(f\"{output_name}.safetensors\").resolve()\n",
        "\n",
        "  new_conv_arg = f\"--new_conv_rank={new_conv_dim}\" if use_conv else \"\"\n",
        "  dynamic_method_arg = f\"--dynamic_method={dynamic_method}\" if use_dynamic else \"\"\n",
        "  dynamic_param_arg = \"--dynamic_param={0:.4f}\".format(dynamic_param) if use_dynamic else \"\"\n",
        "\n",
        "  os.chdir(trainer_dir)\n",
        "\n",
        "  !{venv_python} {Path(\"utils/resize_lora.py\").resolve()} \\\n",
        "    --model={lora} \\\n",
        "    --save_precision={save_precision} \\\n",
        "    --new_rank={new_dim} \\\n",
        "    --save_to={output_file} \\\n",
        "    {new_conv_arg} \\\n",
        "    {dynamic_method_arg} \\\n",
        "    {dynamic_param_arg} \\\n",
        "    {\"--verbose\" if verbose_printing else \"\"} \\\n",
        "    {\"--device=cuda\" if use_gpu else \"\"} \\\n",
        "    {\"--del_conv\" if remove_conv_dims else \"\"} \\\n",
        "    {\"--del_linear\" if remove_linear_dims else \"\"} \\\n",
        "\n",
        "  os.chdir(root_path)\n",
        "\n",
        "def main():\n",
        "  failed, use_conv = validate()\n",
        "  if failed:\n",
        "    return\n",
        "\n",
        "  resize_lora(use_conv)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "pEf-buIXyDLg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}